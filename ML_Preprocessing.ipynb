{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatBCN/ML-PropertyAssessment/blob/main/ML_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Kat Comment: June 4, I read through this notebook to try to understand everything and also experimented with some changes to simplify our data for the modeling. I added comments throughout the notebook for things I didn't understand or think we should discuss.\n",
        "\n",
        "  * I saved prior versions of your work including this notebook and the datasets this notebook created in GitHub, so we can always revert back to an earlier version if needed.\n",
        "  * On June 5, I created an alternate encoding for the imputer using pandas one hot encoding and did an imputation of the training set."
      ],
      "metadata": {
        "id": "x-THdQNs6-2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Data preprocessing pipeline"
      ],
      "metadata": {
        "id": "0ogyj-bbzAh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the environment"
      ],
      "metadata": {
        "id": "dSc0tgzdzMPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "8ShwaJw-yg9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e5238-991a-4de4-9197-7831b24cb50d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/ML/ML-Project\n",
            " \u001b[0m\u001b[01;34mcode\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/\n",
            " Kat-ML-Preprocessing-PropertyAssessment-Buffalo.ipynb\n",
            " ML-BuffaloPropertyAssessment.gdoc\n",
            " ML-DataSplit-PropertyAssessment-Buffalo.ipynb\n",
            " ML-FinalReport-BuffaloPropertyAssessment.gdoc\n",
            " ML-Modeling-LinearRegression-PropertyAssessment-Buffalo.ipynb\n",
            " ML-Modeling-PropertyAssessment-Buffalo.ipynb\n",
            " ML-Preprocessing-PropertyAssessment-Buffalo.ipynb\n",
            " ML-PropertyAssessment-Buffalo.ipynb\n",
            " ML-PropertyAssessment-Strathcona.ipynb\n",
            " ML-Questions.gdoc\n",
            " \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34m'Reference Articles'\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "from google.colab import drive \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import math\n",
        "import pickle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# set options\n",
        "pd.set_option('display.max_columns', None) \n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/ML/ML-Project/\n",
        "%ls "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline functions\n",
        "\n",
        "### Read data split"
      ],
      "metadata": {
        "id": "BU3yeHu9zTrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data_split(filepath):\n",
        "  \n",
        "  df = pd.read_pickle(filepath)\n",
        "\n",
        "  return df\n",
        "  "
      ],
      "metadata": {
        "id": "Ne5UFUWfzftu"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove empty columns\n",
        "\n",
        "Some of the columns in our data are completely or nearly empty. We will get rid of them since we couldn't possibly do good imputation.\n",
        "\n",
        "We set our threshold at 90%"
      ],
      "metadata": {
        "id": "bIrpYM_jzxEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_empty_columns(df, threshold = 0.9):\n",
        "  nas_per_column = df.isna().sum().sort_values()\n",
        "  empty_columns = nas_per_column[nas_per_column / df.shape[0]*100 > 90].index.to_list()\n",
        "  df = df.drop(empty_columns, axis=1)\n",
        "  \n",
        "  print(\"The removed columns with more than 90% missing values are: \" + ', '.join(sorted(empty_columns)))\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "MKZOmIA-0Dx5"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove redundant columns\n",
        "\n",
        "Some of our columns contain values that are redundant or contained by other columns. We will remove those."
      ],
      "metadata": {
        "id": "wtpBPSoL1Ibm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_redundant_columns(df):\n",
        "  redundant_columns = [\"Property Class\", \"City\", \"State\", \"Location\"]\n",
        "  df = df.drop(redundant_columns, axis=1)\n",
        "\n",
        "  print(\"The removed redundant columns are: \" + ', '.join(sorted(redundant_columns)))\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "n6DSQQ4H1HoN"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define datatypes\n",
        "\n",
        "When reading the original files into pandas, we made sure that no datatype inference was being done to avoid unwanted modifications of our data. This function will help us define the correct datatypes."
      ],
      "metadata": {
        "id": "Hcwn05vC2SSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_datatypes(df):\n",
        "  datatypes_dict = {\"category\": [\"Property Class Description\", \"Year Built\", \n",
        "                               \"Overall Condition\", \"Building Style\",\n",
        "                                \"Tax District\", \"Zipcode\", \"Council District\", \n",
        "                               \"Police District\", \"Census Tract\", \n",
        "                               \"Census Block Group\", \"Census Block\",\n",
        "                               \"Neighborhood\", \"Roll\",\n",
        "                               \"Overall Condition\", \"Building Style\", \n",
        "                               \"Heat Type\",\"Basement Type\"],\n",
        "                  \"date\":   [\"Deed Date\"],\n",
        "                  \"int\":    [\"# of Beds\", \"# of Baths\", \"# of Fireplaces\",\n",
        "                             \"Deed Book\", \"Deed Page\", \"Year Built\"],\n",
        "                  \"float\":  [\"Front\", \"Depth\",\"Sale Price\",\"Land Value\", \n",
        "                             \"Total Value\",\"Total Living Area\", \"Longitude\",\n",
        "                             \"Latitude\"],\n",
        "                  \"str\": [\"Print Key\"]\n",
        "                  }\n",
        "\n",
        "  for key in datatypes_dict.keys():\n",
        "    if key == \"date\":\n",
        "      for column in datatypes_dict[key]:\n",
        "        df[column] = pd.to_datetime(df[column])\n",
        "    elif key == \"int\":\n",
        "      for column in datatypes_dict[key]:\n",
        "        df[column] = pd.to_numeric(df[column], errors=\"coerce\") \n",
        "    else:  \n",
        "      for column in datatypes_dict[key]:\n",
        "        df[column] = df[column].astype(key)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "7Htz_tUF2s1N"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decode Property Class"
      ],
      "metadata": {
        "id": "hvMz8pGfbMWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Kat comment: I don't understand what this function is doing. What is its purpose? \n",
        "  - Some strange results: \"INNS,LODGES,BOARDING AND ROOMING HOUSES\" is showing up as previous property class for \"ONE FAMILY DWELLING\" and \"ONE FAMILY DWELLING\" is showing up as previous property class for \"TWO FAMILY DWELLING\""
      ],
      "metadata": {
        "id": "EWa2wYkbqwEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_property_classes(df):\n",
        "  pairs = df[[\"Property Class\", \"Property Class Description\"]].drop_duplicates()\n",
        "  \n",
        "  classes_dict = {}\n",
        "  for i, row in pairs.iterrows():\n",
        "    classes_dict[row[\"Property Class\"]] = row[\"Property Class Description\"]\n",
        "\n",
        "  df[\"Previous Property Class\"] = df[\"Previous Property Class\"].map(classes_dict)\n",
        "  \n",
        "  return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "viNdp8CUbM9r"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decode NAs\n",
        "\n",
        "Some missing values have been encoded using encoded values of the datatype domain instead of null values. We want to decode those."
      ],
      "metadata": {
        "id": "25F4N4LM1_dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_encoded_NAs(df):\n",
        "  df['Deed Date'] = df['Deed Date'].replace(\"09/09/9999\", pd.NaT)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "JQwSzPoW1-8G"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter out properties that are not one or two family dwellings.\n",
        "\n",
        "Among our >90k registered properties, some have no buildings on them, meaning that they're vacant land. We will filter those since these rows are structurally different (are missing many fields) and to reduce the complexity of our dataset before getting to modeling. \n",
        "\n",
        "During data exploration, we also discovered that the majority of properties are One or Two Family dwellings, and each category has an approximately normal distribution of Total Living Area. Our models are limited to these two property types."
      ],
      "metadata": {
        "id": "qO9SxNWW4OUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_property_class(df):\n",
        "  # keeping track of how many rows are removed by filter\n",
        "  original_row_count = df.shape[0]\n",
        "\n",
        "  df = df[df[\"Property Class Description\"].isin([\"ONE FAMILY DWELLING\", \"TWO FAMILY DWELLING\"])]\n",
        "  # remove unused category labels after perfomring the filter operation.\n",
        "  df['Property Class Description'].cat.remove_unused_categories(inplace=True)\n",
        "  \n",
        "  new_row_count = df.shape[0]\n",
        "  print(\"The number of rows removed by filtering property class:\", (original_row_count - new_row_count), \"Ratio retained:\", (new_row_count/original_row_count))  \n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "ixXgcQTe47dn"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering\n",
        "\n",
        "We found some patterns in our textual variables that can be converted into new fields that are more adequate for modelling."
      ],
      "metadata": {
        "id": "GPiZZnxz3MqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def some_feature_engineering(df):\n",
        "  ### Do owners 1 and 2 have the same surname?\n",
        "  # Extract surnames\n",
        "  df[\"Surname1\"] = df[\"Owner1\"].str.split()\n",
        "  df[\"Surname1\"] = [i[0] if i[0] is not None else None for i in df[\"Surname1\"] ] \n",
        "  df[\"Surname2\"] = df[\"Owner2\"].str.split()\n",
        "  df[\"Surname2\"] = [i[0] if type(i) == list else None for i in df[\"Surname2\"] ] \n",
        "\n",
        "  # Create new column for co-owners with the same surname\n",
        "  df[\"SameOwnerFirstName\"] = 0\n",
        "  df.loc[df[\"Surname2\"] == df[\"Surname2\"], \"SameOwnerFirstName\"] = 1\n",
        "\n",
        "\n",
        "  ### Is the owner a corporation, related to Buffalo's administration, or neither of those?\n",
        "  # Check for owners containing corporation names, or containing Buffalo \n",
        "  df[\"Owner1_inc\"] = [2 if i == True else 0 for i in df[\"Owner1\"].str.contains(\"LLC|DIST|CORP|INC|GROUP|STATE|PROPERT|MANAGEMENT\") ] #INC, BUFFALO, CORP, GROUP, MANAGEMENT have samples big enough and modify the price by a lot\n",
        "  df[\"Owner1_buff\"] = [1 if i == True else 0 for i in df[\"Owner1\"].str.contains(\"BUFFALO\")]\n",
        "\n",
        "  # Create new column with the combination of both corporations + buffalo \n",
        "  df[\"OwnershipType\"] = df[\"Owner1_inc\"] - df[\"Owner1_buff\"] \n",
        "\n",
        "  # Put together codes 1 and 2 (similar average target value) and decode\n",
        "  df[\"OwnershipType\"] = [i if i != 2 else 1 for i in df[\"OwnershipType\"]]\n",
        "  OwnershipType_dict = {1: \"Corporation\", -1: \"Buffalo\", 0: \"Person\"}\n",
        "  df[\"OwnershipType\"] = df[\"OwnershipType\"].replace(OwnershipType_dict)\n",
        "\n",
        "  ### Remove deprecated and temporal columns\n",
        "  removable_columns = [\"Owner1\",\"Owner2\", \"Surname1\", \"Surname2\",\n",
        "                     \"Owner1_inc\",\"Owner1_buff\"]\n",
        "  df = df.drop(removable_columns, axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "wUsvplGZ2RE7"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decode bathroom coding\n",
        "The number of bathrooms in a house is usually expressed in terms of full bathrooms and half bathrooms in the U.S.A.\n",
        "\n",
        "When a house has 2 full bathrooms and a half bathroom (no shower/bathtub), it can be expressed as 2.5 bathrooms.\n",
        "\n",
        "An evolution of this coding led to encoding the number of full bathrooms as the full part of the float, and the number of half bathrooms as the decimal part of the float. This way, a house with two full and two half bathrooms will be a 2.2 bathroom house. \n",
        "\n",
        "Both encodings coexist in our dataset. Some houses houses with 2 full and 1 half bath are expressed as 2.5 and some as 2.1. \n",
        "\n",
        "We will take care of variable by adding up the total number of full and half bathrooms. \n",
        "\n",
        "- Kat comment: I don't understand this part. Are 2.2 bathrooms rounded up to 4? I recommend keeping the # of Baths column so that we can compare performance of the original column and our engineered column to make sure this method is actually an improvement."
      ],
      "metadata": {
        "id": "9rfFXkU56yQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_bathrooms(df):\n",
        "  # decode the float values of \"# of Baths\"\n",
        "  totl_bath_list = []\n",
        "  for i in df['# of Baths'].astype(\"str\").str.split(\".\"):\n",
        "    full_baths = int(i[0])\n",
        "    if int(i[1]) != 5:  #assuming that 5 half bathrooms is highly improbable\n",
        "      half_baths = int(i[1])\n",
        "    else:\n",
        "      half_baths = 1\n",
        "    totl_bath_list.append(full_baths + half_baths)\n",
        "  df[\"TotalBaths\"] = totl_bath_list\n",
        "\n",
        "  # Remove deprecated column\n",
        "  # df = df.drop(\"# of Baths\", axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "UixuPA0c6IhP"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove unwanted columns\n",
        "\n",
        "After some preliminary data exploration, many of our variables contain data with too many levels or completely unrelated to our target variable. We will remove these. We are also removing Land Value, a secondary target variable that we will not be looking into. It can't be used to predict because both Land Value and Total Value are assesed at the same time. "
      ],
      "metadata": {
        "id": "Xc-scB1wc0CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_unwanted_columns(df):\n",
        "  unwanted_columns = [\"Print Key\", \"Mail3\", \"Mail4\", \"House Number\", \"Street\", \n",
        "                      \"Deed Book\", \"Deed Page\", \"Deed Date\", \"Land Value\"]\n",
        "  df = df.drop(unwanted_columns, axis=1)\n",
        "  print(\"The removed unwanted columns are: \" + ', '.join(sorted(unwanted_columns)))\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "mW7yfefdcznv"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove alternate location features\n",
        "There are too many categorical variables that represent the location of the property. During one-hot encoding, these will explode the feature space. We will only keep the feature 'neighborhood'\n",
        "\n",
        "This could be combined with the function to remove redundant columns."
      ],
      "metadata": {
        "id": "xXLZU-DQhJOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_location_features(df):\n",
        "  unwanted_location = [\"Tax District\", \"Zipcode\", \"Roll\", \"Council District\",\n",
        "                       \"Police District\", \"Census Tract\", \"Census Block Group\",\n",
        "                       \"Census Block\"]\n",
        "  df = df.drop(unwanted_location, axis=1)\n",
        "  print(\"The removed location features are: \" + ', '.join(sorted(unwanted_location)))\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "l3v8oHQwhGc5"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the pipeline"
      ],
      "metadata": {
        "id": "Q2AjDkUN897S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_preprocessing_pipeline(filepath):\n",
        "  df = read_data_split(filepath)\n",
        "  df = remove_empty_columns(df)\n",
        "  # df = decode_property_classes(df) # I commented out this function because I do not understand its purpose.\n",
        "  df = remove_redundant_columns(df)\n",
        "  df = decode_encoded_NAs(df)\n",
        "  df = define_datatypes(df)\n",
        "  df = filter_by_property_class(df)\n",
        "  df = some_feature_engineering(df)\n",
        "  df = decode_bathrooms(df)\n",
        "  df = remove_unwanted_columns(df)\n",
        "  df = remove_location_features(df)\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "nb0aADfK89Eh"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run preprocessing"
      ],
      "metadata": {
        "id": "As_RVKkA9tZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This runs the pre-processing pipeline on the initial splits of training and validation data and saves the data files in the preprocessed folder.\n",
        "\n",
        "* Kat comment: Is there a reason for not running the preprocessing on the test partition?"
      ],
      "metadata": {
        "id": "E8kbrvVUiJTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [\"train\",\"validation\"]:\n",
        "  print (\"Processing: \", i)\n",
        "  path = \"data/initial_splits/\" + i + \"_BuffaloProperty.pkl\"\n",
        "  df = run_preprocessing_pipeline(path)\n",
        "  df.to_pickle(\"data/preprocessed/\" + i + \"_BuffaloProperty.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73YnwZT39wF7",
        "outputId": "771363b4-473b-4c75-cb6a-ee8237bf2407"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:  train\n",
            "The removed columns with more than 90% missing values are: # of Kitchens, # of Stories, Address, First Story Area, Mail1, Mail2, Previous Owner, Second Story Area, Zipcode Extension\n",
            "The removed redundant columns are: City, Location, Property Class, State\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/categorical.py:2631: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
            "  res = method(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of rows removed by filtering property class: 16606 Ratio retained: 0.6854745534784173\n",
            "The removed unwanted columns are: Deed Book, Deed Date, Deed Page, House Number, Land Value, Mail3, Mail4, Print Key, Street\n",
            "The removed location features are: Census Block, Census Block Group, Census Tract, Council District, Police District, Roll, Tax District, Zipcode\n",
            "Processing:  validation\n",
            "The removed columns with more than 90% missing values are: # of Kitchens, # of Stories, Address, First Story Area, Mail1, Mail2, Previous Owner, Second Story Area, Zipcode Extension\n",
            "The removed redundant columns are: City, Location, Property Class, State\n",
            "The number of rows removed by filtering property class: 5485 Ratio retained: 0.68833456446389\n",
            "The removed unwanted columns are: Deed Book, Deed Date, Deed Page, House Number, Land Value, Mail3, Mail4, Print Key, Street\n",
            "The removed location features are: Census Block, Census Block Group, Census Tract, Council District, Police District, Roll, Tax District, Zipcode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/categorical.py:2631: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
            "  res = method(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier detection and removal"
      ],
      "metadata": {
        "id": "EbQtXRQMqlsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like we have several numeric columns with some encoded NAs. Sale Price, Front, Depth, and other columns have 0s that may have been introduced as a placeholder for a missing value. "
      ],
      "metadata": {
        "id": "6K7nqfudqplL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Decode Sale Price hidden NAs\n",
        "def declare_encoded_NAs(df, min_sale_price_admitted = 100):\n",
        "  # Sale price sometimes is below 100 it shouldn't represent a real value, \n",
        "  # its only simbolic. Often done to \"donate\" properties to family members. \n",
        "  # Sale prices of 0 might simply represent no sale. \n",
        "\n",
        "  df[\"Sale Type\"] = np.NaN\n",
        "  df.loc[ df[\"Sale Price\"] <= min_sale_price_admitted , [\"Sale Type\"]] = \"No Sale\"\n",
        "  df.loc[ df[\"Sale Type\"] != \"No Sale\" , [\"Sale Type\"]] = \"Real Sale\"\n",
        "  df.loc[ df[\"Sale Type\"] == \"No Sale\", [\"Sale Price\"]] = np.NaN  # aprox. 40% NAs\n",
        "\n",
        "  # Front, Depth or Living area\n",
        "  df.loc[ df[\"Front\"] == 0, [\"Front\"]] = np.NaN # less than 100 NAs\n",
        "  df.loc[ df[\"Depth\"] == 0, [\"Depth\"]] = np.NaN # approx 800 NAs\n",
        "\n",
        "  remove_rows = df.loc[ df[\"Total Living Area\"] == 0].index # 17 rows, all missing information about the building\n",
        "  remove_rows.append(df.loc[ df[\"Total Living Area\"] == 1].index) # 1 row\n",
        "  \n",
        "  df = df.drop(remove_rows) # remove the rows missing too much information\n",
        "\n",
        "  return df\n",
        "\n"
      ],
      "metadata": {
        "id": "Kuf9jZuHY1_w"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Kat comment: Are the validation and test partitions using these same functions? I think the thresholds for outliers that are determined on the training set should be the same ones used on all validation and test samples."
      ],
      "metadata": {
        "id": "xmqWG2IjSQ5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numerical_columns(df):\n",
        "  num = df.select_dtypes(include=np.number)  # Get numeric columns\n",
        "  num.drop([\"Latitude\", \"Longitude\", \"SameOwnerFirstName\"], axis=1, inplace=True)\n",
        "  \n",
        "  return num\n",
        "\n",
        "\n",
        "def compute_outlier_df(df):\n",
        "  num = get_numerical_columns(df)\n",
        "\n",
        "  outlier_df = pd.DataFrame(columns=[\"total_outliers\",\"small_outliers\",\"big_outliers\", \"lower_bound\", \"higher_bound\"])\n",
        "  for col in num:\n",
        "    Q1 = num[col].quantile(0.25)\n",
        "    Q3 = num[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    Q1, Q3, IQR\n",
        "\n",
        "    small_outliers = (num[col] < (Q1 - 3 * IQR))\n",
        "    big_outliers = (num[col] > (Q3 + 3 * IQR))\n",
        "    total_outliers = small_outliers.sum() + big_outliers.sum()\n",
        "\n",
        "    outlier_df.loc[col, \"big_outliers\"] = big_outliers.sum()\n",
        "    outlier_df.loc[col, \"small_outliers\"] = small_outliers.sum()\n",
        "    outlier_df.loc[col, \"total_outliers\"] = total_outliers\n",
        "    outlier_df.loc[col, \"lower_bound\"] = Q1 - 3 * IQR\n",
        "    outlier_df.loc[col, \"higher_bound\"] = Q3 + 3 * IQR\n",
        "    \n",
        "  return outlier_df\n",
        "\n",
        "\n",
        "def draw_hists(df):\n",
        "  num = get_numerical_columns(df)\n",
        "  outlier_df = compute_outlier_df(df)\n",
        "  n = num.shape[1]  # Number of cols\n",
        "  fig, axes = plt.subplots(n, 1, figsize=(14, 24))  # create subplots\n",
        "\n",
        "  for ax, col in zip(axes, num):  \n",
        "      p = sns.distplot(num[col], ax=ax)   # Plot histogram\n",
        "      ax.axvline(num[col].mean(), c='k')  # Plot mean\n",
        "      ax.axvline(outlier_df[\"lower_bound\"][col], c=\"r\")\n",
        "      ax.axvline(outlier_df[\"higher_bound\"][col], c=\"r\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "4KVx4Nwvn6M2"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#local_outlier_factor = LocalOutlierFactor(n_neighbors=200)\n",
        "#result = local_outlier_factor.fit_predict(df['Total Value'].values.reshape(-1, 1))\n",
        "#\n",
        "#outliers = result == -1 \n",
        "#no_outliers = result == 1\n",
        "#\n",
        "#plt.rc('axes', axisbelow=True)\n",
        "#plt.hist([df.loc[outliers, \"Total Value\"], df.loc[no_outliers, \"Total Value\"]], color=['lightcoral','lightblue'], log=True)\n",
        "#plt.grid()\n",
        "#plt.legend([\"Outliers\", \"Not outliers\"])\n",
        "#plt.show()\n",
        "#\n",
        "#"
      ],
      "metadata": {
        "id": "99rGIoInb6g7"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Kat comment: - How was 400000 chosen as the cutoff? \n"
      ],
      "metadata": {
        "id": "pQOUe4RX0MO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_target_outliers(df):\n",
        "  # remove rows that are extreme outliers for our target \n",
        "  rows_to_remove = df[df[\"Total Value\"] > 400000].index\n",
        "  df = df.drop(rows_to_remove)\n",
        "  print(\"Removed\", len(rows_to_remove), \"rows\")\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "3VhhPyAlqe8H"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Kat comment - df1 is not defined, this code cannot be run.\n",
        "\n"
      ],
      "metadata": {
        "id": "CeAmC61E0cSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compute_outlier_df(df1)"
      ],
      "metadata": {
        "id": "4o5veDyZv--b"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#draw_hists(df1)"
      ],
      "metadata": {
        "id": "-lg2PBUa3hCB"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Kat comment: This function is setting the values to NA, not removing the whole row if one of the columns is identified as an outlier - is that correct? I find the description of the function confusing.\n",
        "  * I think test samples and validation samples should be processed using the limits learned from the Training set, because in theory we should not be able to see the distribution of all variables in the validation and test sets."
      ],
      "metadata": {
        "id": "BNAMuVUk06Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_predictor_outliers(df, column_tuples):\n",
        "  \"\"\"\n",
        "  remove outliers for the variables specified in a list of column tuples,\n",
        "  the tuples should be specified as (\"column_name\", limits)\n",
        "  limit can be default (function takes the limits from 3xIQR)\n",
        "  or they can be explicit\n",
        "  \"\"\"\n",
        "  new_df = df.copy()\n",
        "\n",
        "  outlier_df = compute_outlier_df(df)\n",
        "\n",
        "\n",
        "  for tpl in column_tuples:\n",
        "    col = tpl[0]\n",
        "    limits = tpl[1]\n",
        "    if limits == \"default\":\n",
        "      limits = (outlier_df.lower_bound[col], outlier_df.higher_bound[col])\n",
        "\n",
        "    new_df.loc[ (new_df[col] < limits[0]) | (new_df[col] > limits[1]) , col] = np.NaN\n",
        "  \n",
        "  return new_df\n",
        "\n"
      ],
      "metadata": {
        "id": "F-MnlDgV6S2l"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#draw_hists(df2)\n",
        "\n"
      ],
      "metadata": {
        "id": "s2b5xdZs89Us"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#categorical_columns = df2.columns[df2.dtypes == \"category\"]\n",
        "#object_columns = df2.columns[df2.dtypes == \"object\"]\n",
        "#\n",
        "#ohe_columns = [*categorical_columns, *object_columns]\n",
        "#\n",
        "#for col in categorical_columns:\n",
        "#  df2[col].cat.remove_unused_categories(inplace=True)\n",
        "#\n",
        "#ohe_df = pd.DataFrame()\n",
        "#for col in ohe_columns:\n",
        "#  ohe_df[col], uniques = pd.factorize(df2[col])\n",
        "#  ohe_df.loc[ohe_df[col] == -1] = np.NaN\n",
        "#\n",
        "#ohe_df\n",
        "#ohe_df[\"Heat Type\"].isna().sum()\n",
        "#df2[\"Heat Type\"].isna().sum()"
      ],
      "metadata": {
        "id": "_bzq2SNrIsY-"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Kat comment: I don't think we should hard code the name of the variables in the def get_catgorical_columns. Remove the commented code if you agree.\n",
        "  - We could also consider defining the object type columns as category type as early as possible in the pipeline.\n",
        "\n"
      ],
      "metadata": {
        "id": "D79m5YZL14pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.preprocessing as preprocessing\n",
        "\n",
        "def get_categorical_columns(df):\n",
        "  object_columns = df.select_dtypes(include='object').columns.tolist()\n",
        "  # convert object type columns to category type\n",
        "  for col in object_columns:\n",
        "    df[col] = df[col].astype(\"category\")\n",
        "  \n",
        "  categorical_columns = df.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "  \"\"\"\n",
        "  # commenting out this code so that we don't need to hard code the column names.\n",
        "  categorical_columns = ['Tax District', 'Property Class Description', 'Zipcode', 'Roll',\n",
        "       'Overall Condition', 'Building Style', 'Heat Type', 'Basement Type',\n",
        "       'Council District', 'Police District', 'Census Tract',\n",
        "       'Census Block Group', 'Census Block', 'Neighborhood']\n",
        "  object_columns = ['Previous Property Class', 'OwnershipType', 'Sale Type']\n",
        "  \"\"\"\n",
        "  # we could update this to only return the categorical columns since we convert objects to categories\n",
        "  return categorical_columns, object_columns"
      ],
      "metadata": {
        "id": "yjt6cGhS4y41"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Kat comment: I don't think the label encoder is the correct function to use in this case. According to the documentation, it is only meant to be used on the target variable, not on training variables.\n",
        "[Label Encoder Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
        "  - I think I found a method that does what you were trying to do with the decoding: It is called inverse_transform and is part of sklearn encoding functions. [Stackoverflow](https://stackoverflow.com/questions/59370700/encoding-data-for-imputation-and-then-decoding)\n",
        "  - In this article, [Label Encoding vs One-Hot Encoding](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd), it explains that algorithms often misinterpret the numbers of label encoding. The imputer calculates neighbors, and is probably misusing the labels as though they have a numerical meaning."
      ],
      "metadata": {
        "id": "0Dy2RAIc422A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_categories(df):\n",
        "  # use LabelEncoder to encode our categorical variables to dummy numbers\n",
        "  categorical_columns, object_columns = get_categorical_columns(df)\n",
        "  columns_to_encode = [*categorical_columns, *object_columns]\n",
        "\n",
        "  for col in categorical_columns:\n",
        "    df[col].cat.remove_unused_categories(inplace=True) # this is probably not the best place to do this because we want categories to be consistent in training and test data\n",
        "\n",
        "  new_df = df.copy()\n",
        "  mask = new_df.isnull()\n",
        "\n",
        "  encoders={}\n",
        "  for col in columns_to_encode:\n",
        "    encoders[col] = preprocessing.LabelEncoder()\n",
        "    encoders[col].fit(df[col].unique())\n",
        "    new_df[col] = encoders[col].transform(new_df[col])\n",
        "\n",
        "  new_df = new_df.where(~mask, np.NaN)\n",
        "\n",
        "  return new_df, encoders\n"
      ],
      "metadata": {
        "id": "2ZjfooQ9RiDC"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_category_decoder(original_df, encoded_df):\n",
        "  categorical_columns, object_columns = get_categorical_columns(df)\n",
        "  columns_to_decode = [*categorical_columns, *object_columns]\n",
        "\n",
        "  label_dict = {}\n",
        "  for col in columns_to_decode:\n",
        "    label_dict[col] = {}\n",
        "    prev_values = original_df[col].unique()\n",
        "    new_values = encoded_df[col].unique()\n",
        "\n",
        "    for new_value, prev_value in zip(new_values, prev_values):\n",
        "      label_dict[col][new_value] = prev_value\n",
        "  \n",
        "  return label_dict\n",
        "\n",
        "\n",
        "def decode_categories(df, decoder):\n",
        "  new_df = df.copy()\n",
        "\n",
        "  label_dict = decoder\n",
        "\n",
        "  categorical_columns, object_columns = get_categorical_columns(df)\n",
        "  columns_to_decode = [*categorical_columns, *object_columns]\n",
        "\n",
        "\n",
        "  for column in columns_to_decode:\n",
        "    new_df[column] = new_df[column].map(label_dict[column])\n",
        "\n",
        "  return new_df\n",
        "  "
      ],
      "metadata": {
        "id": "fvxEtzjVkpkx"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from joblib import dump, load\n",
        "\n",
        "\n",
        "\n",
        "def train_imputer(training_df, imputer_path='models/imputer3.joblib'):\n",
        "  df = training_df.drop(\"Total Value\", axis=1)\n",
        "  complete_df = df.dropna()\n",
        "\n",
        "  imp = IterativeImputer(max_iter=10, random_state=0)\n",
        "  imp.fit(complete_df)\n",
        "\n",
        "  dump(imp, imputer_path) \n",
        "\n",
        "\n",
        "def impute_missing_values(df, imputer_path='models/imputer3.joblib'):\n",
        "  df_no_target = df.drop(\"Total Value\", axis=1)\n",
        "  complete_df = df_no_target.dropna()\n",
        "  missing_rows = df_no_target.isnull().any(axis=1)\n",
        "\n",
        "  imp = load(imputer_path)\n",
        "\n",
        "  new_df = pd.DataFrame(imp.transform(df_no_target), \n",
        "                     columns = df_no_target.columns, index=df_no_target.index)\n",
        "\n",
        "  new_df[\"Total Value\"] = df[\"Total Value\"]\n",
        "\n",
        "  return new_df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bHtKrtLN_Qe6"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kat: Testing imputation with pandas one hot encoding method and fewer columns."
      ],
      "metadata": {
        "id": "C8XKovj5pR3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/50607740/reverse-a-get-dummies-encoding-in-pandas\n",
        "def undummify(df, prefix_sep=\"_\"):\n",
        "    cols2collapse = {\n",
        "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
        "    }\n",
        "    series_list = []\n",
        "    for col, needs_to_collapse in cols2collapse.items():\n",
        "        if needs_to_collapse:\n",
        "            undummified = (\n",
        "                df.filter(like=col)\n",
        "                .idxmax(axis=1)\n",
        "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
        "                .rename(col)\n",
        "            )\n",
        "            series_list.append(undummified)\n",
        "        else:\n",
        "            series_list.append(df[col])\n",
        "    undummified_df = pd.concat(series_list, axis=1)\n",
        "    return undummified_df"
      ],
      "metadata": {
        "id": "mr3Bls3p0C-Y"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During testing, it took 34 seconds to train the imputer."
      ],
      "metadata": {
        "id": "LBvp8TLcvzef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Kat Test with different encoding method\n",
        "train_df = pd.read_pickle(\"data/preprocessed/train_BuffaloProperty.pkl\")\n",
        "\n",
        "train_df = declare_encoded_NAs(train_df)\n",
        "compute_outlier_df(train_df)\n",
        "#draw_hists(df)\n",
        "\n",
        "# this function removes rows\n",
        "df1 = remove_target_outliers(train_df)\n",
        "\n",
        "outlier_tuples = [\n",
        "          (\"Front\", \"default\"), # TO DO: determine limits instead of default\n",
        "          (\"Depth\", \"default\"),\n",
        "          (\"Sale Price\", (0, 400000)),\n",
        "          (\"Total Living Area\", \"default\"),\n",
        "          (\"Front\", \"default\") ]\n",
        "\n",
        "# this function does not remove rows.\n",
        "df2 = remove_predictor_outliers(df1, outlier_tuples)\n",
        "\n",
        "# saving dataframe with missing values so that we can evaluate the randomness.\n",
        "df2.to_pickle(\"data/preprocessed/train_BuffaloProperty_missings.pkl\")\n",
        "\n",
        "df3 = pd.get_dummies(df2)\n",
        "train_imputer(df3, imputer_path='models/imputer3.joblib')\n",
        "df4 = impute_missing_values(df3, imputer_path='models/imputer3.joblib')\n",
        "df5 = undummify(df4)\n",
        "df5.to_pickle(\"data/imputed/train_BuffaloProperty_ohe_imputer3.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4TAGw7R9DZX",
        "outputId": "fd348a23-e21d-41a7-c23f-f1696c1d5663"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 253 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Kat comment: I don't fully understand what outlier_tuples is doing. \n",
        "* Kat comment: Why is sale price set between 0 and 400000?"
      ],
      "metadata": {
        "id": "FO53LyqSnwSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####TESTING\n",
        "\n",
        "train_df = pd.read_pickle(\"data/preprocessed/train_BuffaloProperty.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "train_df = declare_encoded_NAs(train_df)\n",
        "compute_outlier_df(train_df)\n",
        "#draw_hists(df)\n",
        "\n",
        "df1 = remove_target_outliers(train_df)\n",
        "\n",
        "\n",
        "outlier_tuples = [\n",
        "          (\"Front\", \"default\"),\n",
        "          (\"Depth\", \"default\"),\n",
        "          (\"Sale Price\", (0, 400000)),\n",
        "          (\"Total Living Area\", \"default\"),\n",
        "          (\"Front\", \"default\") ]\n",
        "\n",
        "df2 = remove_predictor_outliers(df1, outlier_tuples)\n",
        "\n",
        "df3, encoders3 = encode_categories(df2)\n",
        "decoder = fit_category_decoder(df2, df3)\n",
        "\n",
        "with open('data/imputed/category_decoder_dict.pkl', 'wb') as handle:\n",
        "    pickle.dump(decoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "train_imputer(df3)\n",
        "\n",
        "df4 = impute_missing_values(df3)\n",
        "\n",
        "\n",
        "\n",
        "df4.to_pickle(\"data/imputed/train_BuffaloProperty.pkl\")\n",
        "\n",
        "df5 = decode_categories(df4, decoder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIBFx-OAq_kt",
        "outputId": "dc33d581-58aa-4022-921b-f92af46d90b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 253 rows\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/categorical.py:2631: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
            "  res = method(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.read_pickle(\"data/preprocessed/validation_BuffaloProperty.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "val_df = declare_encoded_NAs(val_df)\n",
        "compute_outlier_df(val_df)\n",
        "#draw_hists(df)\n",
        "\n",
        "vdf1 = remove_target_outliers(val_df)\n",
        "\n",
        "\n",
        "outlier_tuples = [\n",
        "          (\"Front\", \"default\"),\n",
        "          (\"Depth\", \"default\"),\n",
        "          (\"Sale Price\", (0, 400000)),\n",
        "          (\"Total Living Area\", \"default\"),\n",
        "          (\"Front\", \"default\") ]\n",
        "\n",
        "vdf2 = remove_predictor_outliers(vdf1, outlier_tuples)\n",
        "\n",
        "vdf3, vencoders3 = encode_categories(vdf2)\n",
        "vdecoder = fit_category_decoder(vdf2, vdf3)\n",
        "\n",
        "\n",
        "vdf4 = impute_missing_values(vdf3)\n",
        "\n",
        "vdf4.to_pickle(\"data/imputed/validation_BuffaloProperty.pkl\")\n",
        "\n",
        "\n",
        "vdf5 = decode_categories(vdf4, decoder)\n",
        "\n",
        "vdf5\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "FPkYue6OwaaE",
        "outputId": "9f2ddc67-1820-4778-ff8b-c7e1ce774bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/categorical.py:2631: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
            "  res = method(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 88 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Tax District  Front       Depth  \\\n",
              "SBL                                                   \n",
              "1334600001006000          147013   50.0  155.000000   \n",
              "1007600006028000          147004   30.0  127.000000   \n",
              "1337900001046000          147014   32.0  183.000000   \n",
              "1106000001002200606       147001    5.0   78.280872   \n",
              "1004400001004000          147005   29.0  106.000000   \n",
              "...                          ...    ...         ...   \n",
              "0783800001015000          147009   40.0  120.000000   \n",
              "0778000004026000          147008   30.0  110.000000   \n",
              "0787300004004000          147009   53.9   43.000000   \n",
              "1332600001019000          147014   30.0  108.000000   \n",
              "0772600006012000          147008   30.0  112.000000   \n",
              "\n",
              "                    Property Class Description  \\\n",
              "SBL                                              \n",
              "1334600001006000           ONE FAMILY DWELLING   \n",
              "1007600006028000           ONE FAMILY DWELLING   \n",
              "1337900001046000           ONE FAMILY DWELLING   \n",
              "1106000001002200606        ONE FAMILY DWELLING   \n",
              "1004400001004000           TWO FAMILY DWELLING   \n",
              "...                                        ...   \n",
              "0783800001015000           ONE FAMILY DWELLING   \n",
              "0778000004026000           TWO FAMILY DWELLING   \n",
              "0787300004004000           ONE FAMILY DWELLING   \n",
              "1332600001019000           ONE FAMILY DWELLING   \n",
              "0772600006012000           TWO FAMILY DWELLING   \n",
              "\n",
              "                                     Previous Property Class Zipcode Roll  \\\n",
              "SBL                                                                         \n",
              "1334600001006000     INNS,LODGES,BOARDING AND ROOMING HOUSES   14218    1   \n",
              "1007600006028000     INNS,LODGES,BOARDING AND ROOMING HOUSES   14210    1   \n",
              "1337900001046000     INNS,LODGES,BOARDING AND ROOMING HOUSES   14218    1   \n",
              "1106000001002200606  INNS,LODGES,BOARDING AND ROOMING HOUSES   14201    1   \n",
              "1004400001004000                         ONE FAMILY DWELLING   14210    1   \n",
              "...                                                      ...     ...  ...   \n",
              "0783800001015000     INNS,LODGES,BOARDING AND ROOMING HOUSES   14215    1   \n",
              "0778000004026000                         ONE FAMILY DWELLING   14206    1   \n",
              "0787300004004000     INNS,LODGES,BOARDING AND ROOMING HOUSES   14215    1   \n",
              "1332600001019000     INNS,LODGES,BOARDING AND ROOMING HOUSES   14209    1   \n",
              "0772600006012000                         ONE FAMILY DWELLING   14206    1   \n",
              "\n",
              "                        Sale Price  Year Built  Total Living Area  \\\n",
              "SBL                                                                 \n",
              "1334600001006000      64270.284399      1955.0             1066.0   \n",
              "1007600006028000       3000.000000      1817.0             1498.0   \n",
              "1337900001046000      64000.000000      1920.0             1616.0   \n",
              "1106000001002200606  133500.000000      1991.0             1008.0   \n",
              "1004400001004000      45527.853350      1900.0             2120.0   \n",
              "...                            ...         ...                ...   \n",
              "0783800001015000      65625.060127      1951.0             1148.0   \n",
              "0778000004026000      25000.000000      1925.0             2000.0   \n",
              "0787300004004000     120000.000000      1926.0             1232.0   \n",
              "1332600001019000      30000.000000      1910.0             1430.0   \n",
              "0772600006012000      60000.000000      1927.0             1556.0   \n",
              "\n",
              "                    Overall Condition Building Style Heat Type Basement Type  \\\n",
              "SBL                                                                            \n",
              "1334600001006000                    3             01         2             4   \n",
              "1007600006028000                    2             08         2             3   \n",
              "1337900001046000                    3             08         2             4   \n",
              "1106000001002200606                 3             13         2             1   \n",
              "1004400001004000                    3             08         3             4   \n",
              "...                               ...            ...       ...           ...   \n",
              "0783800001015000                    3             04         2             4   \n",
              "0778000004026000                    2             08         2             4   \n",
              "0787300004004000                    3             08         3             4   \n",
              "1332600001019000                    3             08         2             3   \n",
              "0772600006012000                    3             08         2             3   \n",
              "\n",
              "                     # of Fireplaces  # of Beds Council District  \\\n",
              "SBL                                                                \n",
              "1334600001006000                 0.0        3.0            SOUTH   \n",
              "1007600006028000                 0.0        2.0         FILLMORE   \n",
              "1337900001046000                 0.0        4.0            SOUTH   \n",
              "1106000001002200606              0.0        2.0         FILLMORE   \n",
              "1004400001004000                 0.0        6.0           MASTEN   \n",
              "...                              ...        ...              ...   \n",
              "0783800001015000                 0.0        4.0            NORTH   \n",
              "0778000004026000                 0.0        6.0            NORTH   \n",
              "0787300004004000                 1.0        3.0         DELAWARE   \n",
              "1332600001019000                 0.0        4.0            SOUTH   \n",
              "0772600006012000                 0.0        4.0            NORTH   \n",
              "\n",
              "                    Police District Census Tract Census Block Group  \\\n",
              "SBL                                                                   \n",
              "1334600001006000         District A           19                  3   \n",
              "1007600006028000         District C          165                  2   \n",
              "1337900001046000         District A           59                  4   \n",
              "1106000001002200606      District B        71.02                  1   \n",
              "1004400001004000         District C           34                  2   \n",
              "...                             ...          ...                ...   \n",
              "0783800001015000         District D            5                  3   \n",
              "0778000004026000         District D        58.02                  1   \n",
              "0787300004004000         District D           48                  3   \n",
              "1332600001019000         District A           10                  2   \n",
              "0772600006012000         District D           57                  1   \n",
              "\n",
              "                    Census Block       Neighborhood   Latitude  Longitude  \\\n",
              "SBL                                                                         \n",
              "1334600001006000            2032      Hopkins-Tifft  42.845672 -78.831177   \n",
              "1007600006028000            2003  Broadway Fillmore  42.901118 -78.840372   \n",
              "1337900001046000            3036         South Park  42.833233 -78.821461   \n",
              "1106000001002200606         1006            Central  42.884581 -78.886420   \n",
              "1004400001004000            2003           MLK Park  42.914422 -78.842605   \n",
              "...                          ...                ...        ...        ...   \n",
              "0783800001015000            2030         North Park  42.957846 -78.874436   \n",
              "0778000004026000            1003         Black Rock  42.943059 -78.906216   \n",
              "0787300004004000            2032         North Park  42.945251 -78.856878   \n",
              "1332600001019000            2002   Seneca-Cazenovia  42.853791 -78.805985   \n",
              "0772600006012000            1011          Riverside  42.962244 -78.894257   \n",
              "\n",
              "                     SameOwnerFirstName OwnershipType  TotalBaths  Sale Type  \\\n",
              "SBL                                                                            \n",
              "1334600001006000                    1.0        Person         1.0    No Sale   \n",
              "1007600006028000                    0.0   Corporation         1.0  Real Sale   \n",
              "1337900001046000                    0.0        Person         2.0  Real Sale   \n",
              "1106000001002200606                 0.0        Person         2.0  Real Sale   \n",
              "1004400001004000                    0.0        Person         2.0    No Sale   \n",
              "...                                 ...           ...         ...        ...   \n",
              "0783800001015000                    0.0        Person         1.0    No Sale   \n",
              "0778000004026000                    0.0        Person         2.0  Real Sale   \n",
              "0787300004004000                    0.0        Person         1.0  Real Sale   \n",
              "1332600001019000                    0.0   Corporation         1.0  Real Sale   \n",
              "0772600006012000                    0.0   Corporation         2.0  Real Sale   \n",
              "\n",
              "                     Total Value  \n",
              "SBL                               \n",
              "1334600001006000         65000.0  \n",
              "1007600006028000         12000.0  \n",
              "1337900001046000         67000.0  \n",
              "1106000001002200606     150000.0  \n",
              "1004400001004000         22100.0  \n",
              "...                          ...  \n",
              "0783800001015000         75000.0  \n",
              "0778000004026000         23500.0  \n",
              "0787300004004000         83500.0  \n",
              "1332600001019000         46000.0  \n",
              "0772600006012000         57000.0  \n",
              "\n",
              "[12020 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0935059e-ef25-4809-9671-2b3c2a33877a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tax District</th>\n",
              "      <th>Front</th>\n",
              "      <th>Depth</th>\n",
              "      <th>Property Class Description</th>\n",
              "      <th>Previous Property Class</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>Roll</th>\n",
              "      <th>Sale Price</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Total Living Area</th>\n",
              "      <th>Overall Condition</th>\n",
              "      <th>Building Style</th>\n",
              "      <th>Heat Type</th>\n",
              "      <th>Basement Type</th>\n",
              "      <th># of Fireplaces</th>\n",
              "      <th># of Beds</th>\n",
              "      <th>Council District</th>\n",
              "      <th>Police District</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>Census Block Group</th>\n",
              "      <th>Census Block</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>SameOwnerFirstName</th>\n",
              "      <th>OwnershipType</th>\n",
              "      <th>TotalBaths</th>\n",
              "      <th>Sale Type</th>\n",
              "      <th>Total Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBL</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1334600001006000</th>\n",
              "      <td>147013</td>\n",
              "      <td>50.0</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14218</td>\n",
              "      <td>1</td>\n",
              "      <td>64270.284399</td>\n",
              "      <td>1955.0</td>\n",
              "      <td>1066.0</td>\n",
              "      <td>3</td>\n",
              "      <td>01</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>SOUTH</td>\n",
              "      <td>District A</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>2032</td>\n",
              "      <td>Hopkins-Tifft</td>\n",
              "      <td>42.845672</td>\n",
              "      <td>-78.831177</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No Sale</td>\n",
              "      <td>65000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007600006028000</th>\n",
              "      <td>147004</td>\n",
              "      <td>30.0</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14210</td>\n",
              "      <td>1</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>1817.0</td>\n",
              "      <td>1498.0</td>\n",
              "      <td>2</td>\n",
              "      <td>08</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>FILLMORE</td>\n",
              "      <td>District C</td>\n",
              "      <td>165</td>\n",
              "      <td>2</td>\n",
              "      <td>2003</td>\n",
              "      <td>Broadway Fillmore</td>\n",
              "      <td>42.901118</td>\n",
              "      <td>-78.840372</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Corporation</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337900001046000</th>\n",
              "      <td>147014</td>\n",
              "      <td>32.0</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14218</td>\n",
              "      <td>1</td>\n",
              "      <td>64000.000000</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>1616.0</td>\n",
              "      <td>3</td>\n",
              "      <td>08</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>SOUTH</td>\n",
              "      <td>District A</td>\n",
              "      <td>59</td>\n",
              "      <td>4</td>\n",
              "      <td>3036</td>\n",
              "      <td>South Park</td>\n",
              "      <td>42.833233</td>\n",
              "      <td>-78.821461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>67000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106000001002200606</th>\n",
              "      <td>147001</td>\n",
              "      <td>5.0</td>\n",
              "      <td>78.280872</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14201</td>\n",
              "      <td>1</td>\n",
              "      <td>133500.000000</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>FILLMORE</td>\n",
              "      <td>District B</td>\n",
              "      <td>71.02</td>\n",
              "      <td>1</td>\n",
              "      <td>1006</td>\n",
              "      <td>Central</td>\n",
              "      <td>42.884581</td>\n",
              "      <td>-78.886420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>150000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004400001004000</th>\n",
              "      <td>147005</td>\n",
              "      <td>29.0</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>TWO FAMILY DWELLING</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>14210</td>\n",
              "      <td>1</td>\n",
              "      <td>45527.853350</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>2120.0</td>\n",
              "      <td>3</td>\n",
              "      <td>08</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MASTEN</td>\n",
              "      <td>District C</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>2003</td>\n",
              "      <td>MLK Park</td>\n",
              "      <td>42.914422</td>\n",
              "      <td>-78.842605</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No Sale</td>\n",
              "      <td>22100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0783800001015000</th>\n",
              "      <td>147009</td>\n",
              "      <td>40.0</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14215</td>\n",
              "      <td>1</td>\n",
              "      <td>65625.060127</td>\n",
              "      <td>1951.0</td>\n",
              "      <td>1148.0</td>\n",
              "      <td>3</td>\n",
              "      <td>04</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NORTH</td>\n",
              "      <td>District D</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2030</td>\n",
              "      <td>North Park</td>\n",
              "      <td>42.957846</td>\n",
              "      <td>-78.874436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No Sale</td>\n",
              "      <td>75000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0778000004026000</th>\n",
              "      <td>147008</td>\n",
              "      <td>30.0</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>TWO FAMILY DWELLING</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>14206</td>\n",
              "      <td>1</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>08</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NORTH</td>\n",
              "      <td>District D</td>\n",
              "      <td>58.02</td>\n",
              "      <td>1</td>\n",
              "      <td>1003</td>\n",
              "      <td>Black Rock</td>\n",
              "      <td>42.943059</td>\n",
              "      <td>-78.906216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>23500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0787300004004000</th>\n",
              "      <td>147009</td>\n",
              "      <td>53.9</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14215</td>\n",
              "      <td>1</td>\n",
              "      <td>120000.000000</td>\n",
              "      <td>1926.0</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>3</td>\n",
              "      <td>08</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>DELAWARE</td>\n",
              "      <td>District D</td>\n",
              "      <td>48</td>\n",
              "      <td>3</td>\n",
              "      <td>2032</td>\n",
              "      <td>North Park</td>\n",
              "      <td>42.945251</td>\n",
              "      <td>-78.856878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Person</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>83500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332600001019000</th>\n",
              "      <td>147014</td>\n",
              "      <td>30.0</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>INNS,LODGES,BOARDING AND ROOMING HOUSES</td>\n",
              "      <td>14209</td>\n",
              "      <td>1</td>\n",
              "      <td>30000.000000</td>\n",
              "      <td>1910.0</td>\n",
              "      <td>1430.0</td>\n",
              "      <td>3</td>\n",
              "      <td>08</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>SOUTH</td>\n",
              "      <td>District A</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2002</td>\n",
              "      <td>Seneca-Cazenovia</td>\n",
              "      <td>42.853791</td>\n",
              "      <td>-78.805985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Corporation</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>46000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0772600006012000</th>\n",
              "      <td>147008</td>\n",
              "      <td>30.0</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>TWO FAMILY DWELLING</td>\n",
              "      <td>ONE FAMILY DWELLING</td>\n",
              "      <td>14206</td>\n",
              "      <td>1</td>\n",
              "      <td>60000.000000</td>\n",
              "      <td>1927.0</td>\n",
              "      <td>1556.0</td>\n",
              "      <td>3</td>\n",
              "      <td>08</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NORTH</td>\n",
              "      <td>District D</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1011</td>\n",
              "      <td>Riverside</td>\n",
              "      <td>42.962244</td>\n",
              "      <td>-78.894257</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Corporation</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Real Sale</td>\n",
              "      <td>57000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12020 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0935059e-ef25-4809-9671-2b3c2a33877a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0935059e-ef25-4809-9671-2b3c2a33877a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0935059e-ef25-4809-9671-2b3c2a33877a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Jd7pandnoZci",
        "outputId": "5dd32340-b7db-4374-9a5e-6b7b8d7d5763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d2f549c99c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Decoding the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Imputed values\")\n",
        "imp_df = df5[mask[\"Sale Price\"]][[\"Total Value\",\"Sale Price\"]]\n",
        "print(imp_df.head())\n",
        "\n",
        "ori_df = df5[~mask[\"Sale Price\"]][[\"Total Value\",\"Sale Price\"]]\n",
        "print()\n",
        "print(\"Original values\")\n",
        "print(ori_df.head())\n",
        "\n",
        "avg_dif_imp = np.mean(np.abs(imp_df[\"Sale Price\"] - imp_df[\"Total Value\"]))\n",
        "avg_dif_ori = np.mean(np.abs(ori_df[\"Sale Price\"] - ori_df[\"Total Value\"]))\n",
        "print()\n",
        "print(\"Abs average of the difference between Sale Price and Total Value:\")\n",
        "print(\"  for imputed values:  \",avg_dif_imp) \n",
        "print(\"  for original values: \",avg_dif_ori)\n"
      ],
      "metadata": {
        "id": "Njr8MstocfwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_areas = df.loc[:,[\"Front\", \"Depth\", \"Total Living Area\", \"Total Value\"]]\n",
        "df_areas[\"Area\"] = df[\"Front\"]*df[\"Depth\"]\n",
        "corr = df_areas.corr()\n",
        "\n",
        "corr[\"Total Value\"]"
      ],
      "metadata": {
        "id": "FXIZUQwN0GZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}